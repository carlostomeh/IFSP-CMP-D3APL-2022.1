{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Binary Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: use the lecture slides to support your development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data for testing\n",
    "X, y = make_blobs(n_samples=1000, n_features=2, centers=2, cluster_std=1.5, random_state=42)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(f'Labels: {np.unique(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=y_train)\n",
    "plt.xlabel('x1')\n",
    "plt.xlabel('x2')\n",
    "plt.title('Scatter plot: Training Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_test, marker='s')\n",
    "plt.xlabel('x1')\n",
    "plt.xlabel('x2')\n",
    "plt.title('Scatter plot: Testing Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the fake preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./datasets/fake_train.npy', X_train)\n",
    "np.save('./datasets/fake_train_labels.npy', y_train)\n",
    "\n",
    "np.save('./datasets/fake_test.npy', X_test)\n",
    "np.save('./datasets/fake_test_labels.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation\n",
    "### Plan of Attack\n",
    "- Class\n",
    "- Sklearn TemplateClassifier\n",
    "    - https://scikit-learn.org/stable/developers/develop.html\n",
    "    - https://github.com/scikit-learn-contrib/project-template/blob/a06bc1a701fbb320848e4d5295e4477b596078df/skltemplate/_template.py#L74\n",
    "    - https://scikit-learn.org/stable/modules/classes.html#base-classes\n",
    "- Constructor\n",
    "    - learning_rate, n_epochs\n",
    "- \\_\\_str\\_\\_\n",
    "- fit\n",
    "- sigmoid\n",
    "- log_loss\n",
    "- gradient\n",
    "- coef_, intercept_ (@property)\n",
    "- predict_proba\n",
    "- predict\n",
    "- visualize decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class LogisticRegression(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\"Our Logistic Regression implemented from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate : float = 0.001,\n",
    "                 n_epochs : int = 1000, random_state : int = 42):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        learning_rate : float, default=0.001\n",
    "            Learning rate.\n",
    "        n_epochs : int, default=1000\n",
    "            Number of epochs for training (convergence stop).\n",
    "        random_state : int, default=42\n",
    "            Seed used for generating random numbers.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # a special method used to represent a class object as a string, called with print() or str()\n",
    "    def __str__(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, X: ndarray, y: ndarray, verbose: int = 0):\n",
    "        '''Train a Logistic Regression classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "        y: ndarray of shape (n_samples,).\n",
    "            Target (true) labels.\n",
    "        verbose: int, default=0\n",
    "            Verbose flag. Print training information every `verbose` iterations.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "        ### CHECK INPUT ARRAY DIMENSIONS\n",
    "        \n",
    "\n",
    "        ### SETTING SEED\n",
    "\n",
    "        ### PARAMETER INITIALIZATION\n",
    "        # return values from the “standard normal” distribution.\n",
    "\n",
    "        # LEARNING ITERATIONS\n",
    "\n",
    "\n",
    "        ### ASSIGN THE TRAINED PARAMETERS TO THE PRIVATE ATTRIBUTES\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X: ndarray) -> ndarray:\n",
    "        '''Estimate the probability for the positive class of input samples.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features)\n",
    "            Input samples.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "            The estimated probabilities for the positive class of input samples.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def predict(self, X: ndarray) -> ndarray:\n",
    "        '''Predict the labels for input samples.\n",
    "        \n",
    "        Thresholding at probability >= 0.5.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features)\n",
    "            Input samples.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "            Predicted labels of input samples.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing constructor and `__str__`**\n",
    "- evaluate the default hyperparameters\n",
    "- try different valid values for them\n",
    "- try invalid values for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "print('Printing object by print()')\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Displaying object')\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing sigmoid**\n",
    "PS: convert the method to a public static method, by using @staticmethod, and removing the prefix __ and paramater self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our sigmoid function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing log loss**\n",
    "PS: convert the method to a public static method, by using @staticmethod, and removing the prefix __ and paramater self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_debug = np.array([0, 0, 1, 1])\n",
    "p_hat_debug = np.array([0, 0.25, 0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our log loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing input conditions in `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid ndim for X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different n_samples for X and y\n",
    "clf.fit(X_debug, y_debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing `fit()`**\n",
    "PS: use `pdb.set_trace()` inside the main loop of `fit()` for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualizing the Decision Boundary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_1x_1 + w_2x_2 + b = 0$\n",
    "\n",
    "$x_2 = -(b + w_1x_1)/w_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = clf.intercept_\n",
    "w1, w2 = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_decision_line = np.array([X_train[:,0].min(), X_train[:,0].max()])\n",
    "x2_decision_line = -(b + (w1 * x1_decision_line)) / w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=y_train)\n",
    "sns.lineplot(x=x1_decision_line, y=x2_decision_line, color='lightseagreen')\n",
    "plt.xlabel('x1')\n",
    "plt.xlabel('x2')\n",
    "plt.title('Decision Boundary on Training Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_test, marker='s')\n",
    "sns.lineplot(x=x1_decision_line, y=x2_decision_line, color='lightseagreen')\n",
    "plt.xlabel('x1')\n",
    "plt.xlabel('x2')\n",
    "plt.title('Decision Boundary on Testing Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our model inside Sklearn environment\n",
    "Since we designed our linear classifier by following the sklearn standard, we can use our model with all sklearn environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our model within a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Evaluate our classifier with the **Breast Cancer dataset**, [avaible on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer).\n",
    "\n",
    "Suggestion for the experiments:\n",
    "- Fix a given seed (random_state) for reproducibility\n",
    "- Use 80% of the data for training, and 20% for testing - stratified sample\n",
    "- Compared methods:\n",
    "    - Our implementation with default parameters\n",
    "    - Our implementation after fine-tuning the `learning_rate` and `n_epochs`\n",
    "    - [LogisticRegression from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (which is not implemented with Grad. Descent)\n",
    "    - [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.fit) with default parameters\n",
    "- Compute (at least) the F1-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PS:** Only optimize our method against the default (non-optimized) baselines is not a fair comparison. One should also optimize at least the main hyperparameters from the baselines for a more fair comparison. But, this is a simple exercise! Don't worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
